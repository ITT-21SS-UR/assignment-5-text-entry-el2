Author: Lukas Jackermeier
Proofreader: Elisa Valletta

Lee, D., Kim, J., & Oakley, I. (2021, May). FingerText: Exploring and Optimizing Performance for Wearable, Mobile and One-Handed Typing. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-15).

The authors addressed the fact that text input on wearables is extremely difficult in situations where the user is moving around, and there has not been much advancement in HCI yet. They developed and investigated a new, one-handed input method in which users wear a type of glove with sensors on the fingernails. The different possible touch positions between thumb and other fingers are translated to letters. For this, they developed and validated several keyboard layouts with varying amounts of keys and valid touch positions. They tested their final models in a study, which showed that under the "walk" condition, performance could be improved in both speed and accuracy compared to a QWERTY keyboard.


Zhang, M. R., Wang, R., Xu, X., Li, Q., Sharif, A., & Wobbrock, J. O. (2021, May). Voicemoji: Emoji Entry Using Voice for Visually Impaired People. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-18).

In their work, the authors addressed an accessibility problem of modern smartphone keyboards: Until now, blind and visually impaired people have had to use a screen reader and voice feedback to tediously search for the emoji they want to use from a list of emojis. After a qualitative phase in which twelve affected persons were interviewed, the authors used these results to develop a voice-based input method specifically for emojis, Voicemoji.
Voicemoji has four core features for users: it can be started by the voice command "emoji search" to search for an emoji matching a term. With the keyword "insert" and the emoji name, an emoji can be selected directly. In addition, Voicemoji can give context-based emoji recommendations and further commands can be used to customize the emojis and change the color, for example. 
The novel technique was subsequently evaluated both qualitatively and quantitatively through a user study with 12 participants. They were able to show that the use of voicemoji reduced the input time by 91.2% and increased user satisfaction as a result.


Zhang, M. R., Zhai, S. (2021, May): PhraseFlow: Designs and Empirical Studies of Phrase-Level Input

Zhang and Zhai implemented an input auto-correction system for use on mobile devices that takes future context into consideration before correcting. While most common auto-correction systems work on word-level, meaning each word is corrected immediately after a wrong input was detected, PhraseFlow works on phrase-level, meaning that inputs can be automatically corrected at a later time when the context of the phrase is more clear. This leads to an overall higher correction accuracy. However, when PhraseFlow was first tested, the user's input speed was significantly slower than with regular mobile keyboards. The authors developed a new iteration of PhaseFlow based on their gathered data and qualitative user feedback, which then showed no significant difference in typing speed compared to regular auto-correction features, while also showing a significant improvement in Word Error Rate.
