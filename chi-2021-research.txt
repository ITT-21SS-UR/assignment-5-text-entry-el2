Author: Lukas Jackermeier
Proofreader: Elisa Valletta

Lee, D., Kim, J., & Oakley, I. (2021, May). FingerText: Exploring and Optimizing Performance for Wearable, Mobile and One-Handed Typing. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-15).

The authors addressed the fact that text input on wearables is extremely difficult in situations where the user is moving around, and there has not been much advancement in HCI yet. They developed and investigated a new, one-handed input method in which users wear a type of glove with sensors on the fingernails. The different possible touches between thumb and fingers are translated as letters for the input following one of many keyboard keyboards. For this, they developed and validated several keyboard layouts. They tested their final models in a study, which showed that under the "walk" condition, performance could be improved in both speed and accuracy compared to a QWERTY keyboard.

Zhang, M. R., Wang, R., Xu, X., Li, Q., Sharif, A., & Wobbrock, J. O. (2021, May). Voicemoji: Emoji Entry Using Voice for Visually Impaired People. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-18).

In their work, the authors addressed a problem that only affects a small target group of users when entering text: Until now, blind and visually impaired people have had to use a screen reader and voice feedback to tediously search for the emoji they want to use from a list of emojis. After a qualitative phase in which twelve affected persons were interviewed, the authors used these results to develop a voice-based input method specifically for emojis, Voicemoji.
Voicemoji has four core features for users: it can be started by the voice command "emoji search" to search for an emoji matching a term. With the keyword "insert" and the emoji name, an emoji can be selected directly. In addition, Voicemoji can give context-based emoji recommendations and further commands can be used to customize the emojis and change the color, for example. 
The novell technique was subsequently evaluated both qualitatively and quantitatively through a user study with 12 subjects. They were able to show that the use of voicemoji reduced the input time by 91.2% and increased user satisfaction as a result.

Hedeshy, R., Kumar, C., Menges, R., & Staab, S. (2021, May). Hummer: Text Entry by Gaze and Hum. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-11).

In this work, the authors have dealt with text input for physically impaired people who cannot use their hands to use a pen or keyboard. For this target group it is common to select single letters via eye tracking. In order to improve the error rate and the user experience, the authors designed two systems, each using speech input and humming to improve the eye tracking. In both systems, buzzing signals tell the system when the input of a word via eye tracking begins and ends. Hummer by continuous buzzing during the word input and HumHum by short buzzing at the beginning and end of the word. In addition, word suggestions for the current input are suggested directly on the display. 
Both systems were tested in a user study with 12 test persons and compared with an already existing system. Both the speed, the error rate and the subjective evaluation of the participants were better for the new systems, with the Hummer system outperforming the HumHum system.
